{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.initializers import RandomNormal, Zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequencePoolingLayer(Layer):\n",
    "    \"\"\"The SequencePoolingLayer is used to apply pooling operation(sum,mean,max) on variable-length sequence feature/multi-value feature.\n",
    "\n",
    "      Input shape\n",
    "        - A list of two  tensor [seq_value,seq_len]\n",
    "\n",
    "        - seq_value is a 3D tensor with shape: ``(batch_size, T, embedding_size)``\n",
    "\n",
    "        - seq_len is a 2D tensor with shape : ``(batch_size, 1)``,indicate valid length of each sequence.\n",
    "\n",
    "      Output shape\n",
    "        - 3D tensor with shape: ``(batch_size, 1, embedding_size)``.\n",
    "\n",
    "      Arguments\n",
    "        - **mode**:str.Pooling operation to be used,can be sum,mean or max.\n",
    "\n",
    "        - **supports_masking**:If True,the input need to support masking.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, mode='mean', supports_masking=False, **kwargs):\n",
    "\n",
    "        if mode not in ['sum', 'mean', 'max']:\n",
    "            raise ValueError(\"mode must be sum or mean\")\n",
    "        self.mode = mode\n",
    "        self.eps = tf.constant(1e-8, tf.float32)\n",
    "        super(SequencePoolingLayer, self).__init__(**kwargs)\n",
    "\n",
    "        self.supports_masking = supports_masking\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        if not self.supports_masking:\n",
    "            self.seq_len_max = int(input_shape[0][1])\n",
    "        super(SequencePoolingLayer, self).build(input_shape)  # Be sure to call this somewhere!\n",
    "\n",
    "    def call(self, seq_value_len_list, mask=None, **kwargs):\n",
    "        if self.supports_masking:\n",
    "            if mask is None:\n",
    "                raise ValueError(\n",
    "                    \"When supports_masking=True,input must support masking\")\n",
    "            uiseq_embed_list = seq_value_len_list\n",
    "            mask = tf.cast(mask, tf.float32)  # tf.to_float(mask)\n",
    "            user_behavior_length = tf.reduce_sum(mask, axis=-1, keepdims=True)\n",
    "            mask = tf.expand_dims(mask, axis=2)\n",
    "        else:\n",
    "            uiseq_embed_list, user_behavior_length = seq_value_len_list\n",
    "\n",
    "            mask = tf.sequence_mask(user_behavior_length,\n",
    "                                    self.seq_len_max, dtype=tf.float32)\n",
    "            mask = tf.transpose(mask, (0, 2, 1))\n",
    "\n",
    "        embedding_size = uiseq_embed_list.shape[-1]\n",
    "\n",
    "        mask = tf.tile(mask, [1, 1, embedding_size])\n",
    "\n",
    "        if self.mode == \"max\":\n",
    "            hist = uiseq_embed_list - (1-mask) * 1e9\n",
    "            return tf.reduce_max(hist, 1, keepdims=True)\n",
    "\n",
    "        hist = tf.reduce_sum(uiseq_embed_list * mask, 1, keepdims=False)\n",
    "\n",
    "        if self.mode == \"mean\":\n",
    "            hist = tf.divide(hist, tf.cast(user_behavior_length, tf.float32) + self.eps)\n",
    "\n",
    "        hist = tf.expand_dims(hist, axis=1)\n",
    "        return hist\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.supports_masking:\n",
    "            return (None, 1, input_shape[-1])\n",
    "        else:\n",
    "            return (None, 1, input_shape[0][-1])\n",
    "\n",
    "    def compute_mask(self, inputs, mask):\n",
    "        return None\n",
    "\n",
    "    def get_config(self, ):\n",
    "        config = {'mode': self.mode, 'supports_masking': self.supports_masking}\n",
    "        base_config = super(SequencePoolingLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabelAwareAttention(Layer):\n",
    "    def __init__(self, k_max, pow_p=1, **kwargs):\n",
    "        self.k_max = k_max\n",
    "        self.pow_p = pow_p\n",
    "        super(LabelAwareAttention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # Be sure to call this somewhere!\n",
    "        self.embedding_size = input_shape[0][-1]\n",
    "        super(LabelAwareAttention, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, training=None, **kwargs):\n",
    "        keys = inputs[0]\n",
    "        query = inputs[1]\n",
    "        weight = tf.reduce_sum(keys * query, axis=-1, keepdims=True)\n",
    "        weight = tf.pow(weight, self.pow_p)  # [x,k_max,1]\n",
    "\n",
    "        if len(inputs) == 3:\n",
    "            k_user = tf.cast(tf.maximum(\n",
    "                1.,\n",
    "                tf.minimum(\n",
    "                    tf.cast(self.k_max, dtype=\"float32\"),  # k_max\n",
    "                    tf.math.log1p(tf.cast(inputs[2], dtype=\"float32\")) / tf.math.log(2.)  # hist_len\n",
    "                )\n",
    "            ), dtype=\"int64\")\n",
    "            \n",
    "            seq_mask = tf.transpose(tf.sequence_mask(k_user, self.k_max), [0, 2, 1])\n",
    "            padding = tf.ones_like(seq_mask, dtype=tf.float32) * (-2 ** 32 + 1)  # [x,k_max,1]\n",
    "            weight = tf.where(seq_mask, weight, padding)\n",
    "\n",
    "        weight = tf.nn.softmax(weight, name=\"weight\")\n",
    "        output = tf.reduce_sum(keys * weight, axis=1)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.embedding_size)\n",
    "\n",
    "    def get_config(self, ):\n",
    "        config = {'k_max': self.k_max, 'pow_p': self.pow_p}\n",
    "        base_config = super(LabelAwareAttention, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CapsuleLayer(Layer):\n",
    "    def __init__(self, input_units, out_units, max_len, k_max, iteration_times=3,\n",
    "                 init_std=1.0, **kwargs):\n",
    "        self.input_units = input_units\n",
    "        self.out_units = out_units\n",
    "        self.max_len = max_len\n",
    "        self.k_max = k_max\n",
    "        self.iteration_times = iteration_times\n",
    "        self.init_std = init_std\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.routing_logits = self.add_weight(shape=[1, self.k_max, self.max_len],\n",
    "                                              initializer=RandomNormal(stddev=self.init_std),\n",
    "                                              trainable=False, name=\"B\", dtype=tf.float32)\n",
    "        self.bilinear_mapping_matrix = self.add_weight(shape=[self.input_units, self.out_units],\n",
    "                                                       initializer=RandomNormal(stddev=self.init_std),\n",
    "                                                       name=\"S\", dtype=tf.float32)\n",
    "        super(CapsuleLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        behavior_embddings, seq_len = inputs\n",
    "        batch_size = tf.shape(behavior_embddings)[0]\n",
    "        seq_len_tile = tf.tile(seq_len, [1, self.k_max])\n",
    "\n",
    "        for i in range(self.iteration_times):\n",
    "            mask = tf.sequence_mask(seq_len_tile, self.max_len)\n",
    "            pad = tf.ones_like(mask, dtype=tf.float32) * (-2 ** 32 + 1)\n",
    "            routing_logits_with_padding = tf.where(mask, tf.tile(self.routing_logits, [batch_size, 1, 1]), pad)\n",
    "            weight = tf.nn.softmax(routing_logits_with_padding)\n",
    "            behavior_embdding_mapping = tf.tensordot(behavior_embddings, self.bilinear_mapping_matrix, axes=1)\n",
    "            Z = tf.matmul(weight, behavior_embdding_mapping)\n",
    "            interest_capsules = squash(Z)\n",
    "            delta_routing_logits = tf.reduce_sum(\n",
    "                tf.matmul(interest_capsules, tf.transpose(behavior_embdding_mapping, perm=[0, 2, 1])),\n",
    "                axis=0, keepdims=True\n",
    "            )\n",
    "            self.routing_logits.assign_add(delta_routing_logits)\n",
    "\n",
    "        interest_capsules = tf.reshape(interest_capsules, [-1, self.k_max, self.out_units])\n",
    "        return interest_capsules\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.k_max, self.out_units)\n",
    "\n",
    "    def get_config(self, ):\n",
    "        config = {'input_units': self.input_units, 'out_units': self.out_units, 'max_len': self.max_len,\n",
    "                  'k_max': self.k_max, 'iteration_times': self.iteration_times, \"init_std\": self.init_std}\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "    \n",
    "\n",
    "\n",
    "def squash(inputs):\n",
    "    vec_squared_norm = tf.reduce_sum(tf.square(inputs), axis=-1, keepdims=True)\n",
    "    scalar_factor = vec_squared_norm / (1 + vec_squared_norm) / tf.sqrt(vec_squared_norm + 1e-8)\n",
    "    vec_squashed = scalar_factor * inputs\n",
    "    \n",
    "    return vec_squashed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, concatenate, Flatten, Dense, Dropout\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n",
    "def tile_user_otherfeat(user_other_feature, k_max):\n",
    "        return tf.tile(tf.expand_dims(user_other_feature, -2), [1, k_max, 1])\n",
    "\n",
    "\n",
    "def mind(\n",
    "    sparse_input_length=1,\n",
    "    dense_input_length=1,\n",
    "    sparse_seq_input_length=50,\n",
    "    \n",
    "    embedding_dim = 64,\n",
    "    neg_sample_num = 10,\n",
    "    user_hidden_unit_list = [128, 64],\n",
    "    k_max = 5,\n",
    "    p = 1,\n",
    "    dynamic_k = True\n",
    "    ):\n",
    "    \n",
    "\n",
    "    \n",
    "    # 1. Input layer\n",
    "    user_id_input_layer = Input(shape=(sparse_input_length, ), name=\"user_id_input_layer\")\n",
    "    gender_input_layer = Input(shape=(sparse_input_length, ), name=\"gender_input_layer\")\n",
    "    age_input_layer = Input(shape=(sparse_input_length, ), name=\"age_input_layer\")\n",
    "    occupation_input_layer = Input(shape=(sparse_input_length, ), name=\"occupation_input_layer\")\n",
    "    zip_input_layer = Input(shape=(sparse_input_length, ), name=\"zip_input_layer\")\n",
    "    \n",
    "    \n",
    "    user_click_item_seq_input_layer = Input(shape=(sparse_seq_input_length, ), name=\"user_click_item_seq_input_layer\")\n",
    "    user_click_item_seq_length_input_layer = Input(shape=(sparse_input_length, ), name=\"user_click_item_seq_length_input_layer\")\n",
    "    \n",
    "    \n",
    "    pos_item_sample_input_layer = Input(shape=(sparse_input_length, ), name=\"pos_item_sample_input_layer\")\n",
    "    neg_item_sample_input_layer = Input(shape=(neg_sample_num, ), name=\"neg_item_sample_input_layer\")\n",
    "\n",
    "\n",
    "    \n",
    "    # 2. Embedding layer\n",
    "    user_id_embedding_layer = Embedding(6040+1, embedding_dim, mask_zero=True, name='user_id_embedding_layer')(user_id_input_layer)\n",
    "    gender_embedding_layer = Embedding(2+1, embedding_dim, mask_zero=True, name='gender_embedding_layer')(gender_input_layer)\n",
    "    age_embedding_layer = Embedding(7+1, embedding_dim, mask_zero=True, name='age_embedding_layer')(age_input_layer)\n",
    "    occupation_embedding_layer = Embedding(21+1, embedding_dim, mask_zero=True, name='occupation_embedding_layer')(occupation_input_layer)\n",
    "    zip_embedding_layer = Embedding(3439+1, embedding_dim, mask_zero=True, name='zip_embedding_layer')(zip_input_layer)\n",
    "    \n",
    "    item_id_embedding_layer = Embedding(3706+1, embedding_dim, mask_zero=True, name='item_id_embedding_layer')\n",
    "    pos_item_sample_embedding_layer = item_id_embedding_layer(pos_item_sample_input_layer)\n",
    "    neg_item_sample_embedding_layer = item_id_embedding_layer(neg_item_sample_input_layer)\n",
    "    \n",
    "    user_click_item_seq_embedding_layer = item_id_embedding_layer(user_click_item_seq_input_layer)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    ### ********** ###\n",
    "    # 3. user part\n",
    "    ### ********** ###\n",
    "    \n",
    "    # 3.1 pooling layer\n",
    "    user_click_item_seq_embedding_layer_pooling = SequencePoolingLayer()([user_click_item_seq_embedding_layer, \\\n",
    "                                                                          user_click_item_seq_length_input_layer])\n",
    "    \n",
    "    print(\"user_click_item_seq_embedding_layer_pooling\", user_click_item_seq_embedding_layer_pooling)\n",
    "    \n",
    "    \n",
    "    # 3.2 capsule layer\n",
    "    high_capsule = CapsuleLayer(input_units=embedding_dim,\n",
    "                                out_units=embedding_dim, max_len=sparse_seq_input_length,\n",
    "                                k_max=k_max)([user_click_item_seq_embedding_layer, user_click_item_seq_length_input_layer])\n",
    "    \n",
    "    print(\"high_capsule: \", high_capsule)\n",
    "    \n",
    "\n",
    "    # 3.3 Concat \"sparse\" embedding & \"sparse_seq\" embedding, and tile embedding\n",
    "    other_user_embedding_layer = Flatten()(concatenate([user_id_embedding_layer, gender_embedding_layer, age_embedding_layer,\n",
    "                                       occupation_embedding_layer, zip_embedding_layer, user_click_item_seq_embedding_layer_pooling], \n",
    "                                       axis=-1)\n",
    "                                    )\n",
    "    \n",
    "    print(\"other_user_embedding_layer: \", other_user_embedding_layer)\n",
    "    \n",
    "    \n",
    "    other_user_embedding_layer = tf.keras.layers.Lambda(tile_user_otherfeat, arguments={'k_max': k_max})(other_user_embedding_layer)\n",
    "    print(\"other_user_embedding_layer: \", other_user_embedding_layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # 3.4 user dnn part\n",
    "    \n",
    "    user_deep_input = concatenate([other_user_embedding_layer, high_capsule], axis=-1)\n",
    "    print(\"user_deep_input: \", user_deep_input)\n",
    "\n",
    "    \n",
    "    for i, u in enumerate(user_hidden_unit_list):\n",
    "        user_deep_input = Dense(u, activation=\"relu\", name=\"FC_{0}\".format(i+1))(user_deep_input)\n",
    "        #user_deep_input = Dropout(0.3)(user_deep_input)\n",
    "        \n",
    "    print(\"user_deep_input: \", user_deep_input)\n",
    "    \n",
    "    dynamic_k = True\n",
    "    if dynamic_k:\n",
    "        user_embedding_final = LabelAwareAttention(k_max=k_max, pow_p=p, )(\\\n",
    "                                    [user_deep_input, pos_item_sample_embedding_layer, user_click_item_seq_length_input_layer])\n",
    "    else:\n",
    "        user_embedding_final = LabelAwareAttention(k_max=k_max, pow_p=p, )(\\\n",
    "                                    [user_deep_input, pos_item_sample_embedding_layer])\n",
    "    \n",
    "    \n",
    "    user_embedding_final = tf.expand_dims(user_embedding_final, 1)\n",
    "    print(\"user_embedding_final: \", user_embedding_final)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### ********** ###\n",
    "    # 4. item part\n",
    "    ### ********** ###\n",
    "\n",
    "    item_embedding_layer = concatenate([pos_item_sample_embedding_layer, neg_item_sample_embedding_layer], \\\n",
    "                                       axis=1)\n",
    "    \n",
    "    item_embedding_layer = tf.transpose(item_embedding_layer, [0,2,1])\n",
    "    \n",
    "    print(\"item_embedding_layer: \", item_embedding_layer)\n",
    "\n",
    "    ### ********** ###\n",
    "    # 5. Output\n",
    "    ### ********** ###\n",
    "    dot_output = tf.matmul(user_embedding_final, item_embedding_layer)\n",
    "    print(dot_output)\n",
    "    dot_output = tf.nn.softmax(dot_output) # 输出11个值，index为0的值是正样本，负样本的索引位置为[1-10]\n",
    "    \n",
    "    print(dot_output)\n",
    "    user_inputs_list = [user_id_input_layer, gender_input_layer, age_input_layer, \\\n",
    "                        occupation_input_layer, zip_input_layer, \\\n",
    "                        user_click_item_seq_input_layer, user_click_item_seq_length_input_layer]\n",
    "    \n",
    "    item_inputs_list = [pos_item_sample_input_layer, neg_item_sample_input_layer]\n",
    "\n",
    "    model = Model(inputs = user_inputs_list + item_inputs_list,\n",
    "                  outputs = dot_output)\n",
    "    \n",
    "    \n",
    "    #print(model.summary())\n",
    "    #tf.keras.utils.plot_model(model, to_file='MIND_model.png', show_shapes=True)\n",
    "\n",
    "\n",
    "    model.__setattr__(\"user_input\", user_inputs_list)\n",
    "    model.__setattr__(\"user_embedding\", user_deep_input)\n",
    "    \n",
    "    model.__setattr__(\"item_input\", pos_item_sample_input_layer)\n",
    "    model.__setattr__(\"item_embedding\", pos_item_sample_embedding_layer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_click_item_seq_embedding_layer_pooling Tensor(\"sequence_pooling_layer_50/Identity:0\", shape=(None, 1, 64), dtype=float32)\n",
      "high_capsule:  Tensor(\"capsule_layer_53/Identity:0\", shape=(None, 5, 64), dtype=float32)\n",
      "other_user_embedding_layer:  Tensor(\"flatten_44/Identity:0\", shape=(None, 384), dtype=float32)\n",
      "other_user_embedding_layer:  Tensor(\"lambda_43/Identity:0\", shape=(None, 5, 384), dtype=float32)\n",
      "user_deep_input:  Tensor(\"concatenate_119/Identity:0\", shape=(None, 5, 448), dtype=float32)\n",
      "user_deep_input:  Tensor(\"FC_2_41/Identity:0\", shape=(None, 5, 64), dtype=float32)\n",
      "user_embedding_final:  Tensor(\"ExpandDims_2:0\", shape=(None, 1, 64), dtype=float32)\n",
      "item_embedding_layer:  Tensor(\"transpose_29:0\", shape=(None, 64, 11), dtype=float32)\n",
      "Tensor(\"MatMul_24:0\", shape=(None, 1, 11), dtype=float32)\n",
      "Tensor(\"Softmax_24:0\", shape=(None, 1, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#model = mind()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data generator\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def init_output():\n",
    "    user_id = []\n",
    "    gender = []\n",
    "    age = []\n",
    "    occupation = []\n",
    "    zip = []\n",
    "    hist_movie_id = []\n",
    "    hist_len = []\n",
    "    pos_movie_id = []\n",
    "    neg_movie_id = []\n",
    "\n",
    "\n",
    "    return user_id, gender, age, occupation, zip, \\\n",
    "        hist_movie_id, hist_len, pos_movie_id, neg_movie_id\n",
    "\n",
    "\n",
    "def file_generator(input_path, batch_size):\n",
    "\n",
    "    user_id, gender, age, occupation, zip, \\\n",
    "        hist_movie_id, hist_len, pos_movie_id, neg_movie_id = init_output()\n",
    "\n",
    "    cnt = 0\n",
    "    \n",
    "    num_lines = sum([1 for line in open(input_path)])\n",
    "\n",
    "    while True:\n",
    "\n",
    "        with open(input_path, 'r') as f:\n",
    "            for line in f.readlines():\n",
    "\n",
    "                buf = line.strip().split('\\t')\n",
    "\n",
    "                user_id.append(int(buf[0]))\n",
    "                gender.append(int(buf[1]))\n",
    "                age.append(int(buf[2]))\n",
    "                occupation.append(int(buf[3]))\n",
    "                zip.append(int(buf[4]))\n",
    "                hist_movie_id.append(np.array([int(i) for i in buf[5].strip().split(\",\")]))\n",
    "                hist_len.append(int(buf[6]))\n",
    "                pos_movie_id.append(int(buf[7]))\n",
    "                neg_movie_id.append(np.array([int(i) for i in buf[8].strip().split(\",\")]))\n",
    "\n",
    "                cnt += 1\n",
    "\n",
    "                if cnt % batch_size == 0 or cnt == num_lines:\n",
    "                    user_id = np.array(user_id, dtype='int32')\n",
    "                    gender = np.array(gender, dtype='int32')\n",
    "                    age = np.array(age, dtype='int32')\n",
    "                    occupation = np.array(occupation, dtype='int32')\n",
    "                    zip = np.array(zip, dtype='int32')\n",
    "                    hist_movie_id = np.array(hist_movie_id, dtype='int32')\n",
    "                    hist_len = np.array(hist_len, dtype='int32')\n",
    "                    pos_movie_id = np.array(pos_movie_id, dtype='int32')\n",
    "                    neg_movie_id = np.array(neg_movie_id, dtype='int32')\n",
    "\n",
    "                    label = np.zeros(len(user_id)) # 正样本的index位置为0, 10个负样本的索引位置为[1-10]\n",
    "\n",
    "                    yield [user_id, gender, age, occupation, zip, hist_movie_id, hist_len, pos_movie_id, neg_movie_id], label\n",
    "\n",
    "                    user_id, gender, age, occupation, zip, hist_movie_id, hist_len, pos_movie_id, neg_movie_id = init_output()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_train:  988129\n",
      "n_val:  6040\n",
      "steps_per_epoch:  989\n",
      "validation_steps:  7\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "\n",
    "train_path = \"train.txt\"\n",
    "val_path = \"test.txt\"\n",
    "batch_size = 1000\n",
    "\n",
    "n_train = sum([1 for i in open(train_path)])\n",
    "n_val = sum([1 for i in open(val_path)])\n",
    "\n",
    "train_steps = n_train / batch_size\n",
    "train_steps_ = n_train // batch_size\n",
    "validation_steps = n_val / batch_size\n",
    "validation_steps_ = n_val // batch_size\n",
    "\n",
    "\n",
    "train_generator = file_generator(train_path, batch_size)\n",
    "val_generator = file_generator(val_path, batch_size)\n",
    "\n",
    "steps_per_epoch = train_steps_ if train_steps==train_steps_ else train_steps_ + 1\n",
    "validation_steps = validation_steps_ if validation_steps==validation_steps_ else validation_steps_ + 1\n",
    "\n",
    "print(\"n_train: \", n_train)\n",
    "print(\"n_val: \", n_val)\n",
    "\n",
    "print(\"steps_per_epoch: \", steps_per_epoch)\n",
    "print(\"validation_steps: \", validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_click_item_seq_embedding_layer_pooling Tensor(\"sequence_pooling_layer_51/Identity:0\", shape=(None, 1, 64), dtype=float32)\n",
      "high_capsule:  Tensor(\"capsule_layer_54/Identity:0\", shape=(None, 5, 64), dtype=float32)\n",
      "other_user_embedding_layer:  Tensor(\"flatten_45/Identity:0\", shape=(None, 384), dtype=float32)\n",
      "other_user_embedding_layer:  Tensor(\"lambda_44/Identity:0\", shape=(None, 5, 384), dtype=float32)\n",
      "user_deep_input:  Tensor(\"concatenate_122/Identity:0\", shape=(None, 5, 448), dtype=float32)\n",
      "user_deep_input:  Tensor(\"FC_2_42/Identity:0\", shape=(None, 5, 64), dtype=float32)\n",
      "user_embedding_final:  Tensor(\"ExpandDims_3:0\", shape=(None, 1, 64), dtype=float32)\n",
      "item_embedding_layer:  Tensor(\"transpose_30:0\", shape=(None, 64, 11), dtype=float32)\n",
      "Tensor(\"MatMul_25:0\", shape=(None, 1, 11), dtype=float32)\n",
      "Tensor(\"Softmax_25:0\", shape=(None, 1, 11), dtype=float32)\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 989 steps, validate for 7 steps\n",
      "Epoch 1/2\n",
      "989/989 [==============================] - 137s 139ms/step - loss: 1.6103 - sparse_categorical_accuracy: 0.4047 - val_loss: 1.5822 - val_sparse_categorical_accuracy: 0.4189\n",
      "Epoch 2/2\n",
      "989/989 [==============================] - 134s 135ms/step - loss: 1.3641 - sparse_categorical_accuracy: 0.4875 - val_loss: 1.5168 - val_sparse_categorical_accuracy: 0.4504\n"
     ]
    }
   ],
   "source": [
    "# train model\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "callbacks = [early_stopping_cb]\n",
    "\n",
    "\n",
    "model = mind()\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', \\\n",
    "    optimizer=Adam(lr=1e-3), \\\n",
    "    metrics=['sparse_categorical_accuracy'])\n",
    "# loss=\"sparse_categorical_accuracy\"的应用方式参见：https://mp.weixin.qq.com/s/H4ET0bO_xPm8TNqltMt3Fg\n",
    "\n",
    "\n",
    "\n",
    "history = model.fit(train_generator, \\\n",
    "                    epochs=2, \\\n",
    "                    steps_per_epoch = steps_per_epoch, \\\n",
    "                    callbacks = callbacks, \n",
    "                    validation_data = val_generator, \\\n",
    "                    validation_steps = validation_steps, \\\n",
    "                    shuffle=True\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('mind_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_click_item_seq_embedding_layer_pooling Tensor(\"sequence_pooling_layer_52/Identity:0\", shape=(None, 1, 64), dtype=float32)\n",
      "high_capsule:  Tensor(\"capsule_layer_55/Identity:0\", shape=(None, 5, 64), dtype=float32)\n",
      "other_user_embedding_layer:  Tensor(\"flatten_46/Identity:0\", shape=(None, 384), dtype=float32)\n",
      "other_user_embedding_layer:  Tensor(\"lambda_45/Identity:0\", shape=(None, 5, 384), dtype=float32)\n",
      "user_deep_input:  Tensor(\"concatenate_125/Identity:0\", shape=(None, 5, 448), dtype=float32)\n",
      "user_deep_input:  Tensor(\"FC_2_43/Identity:0\", shape=(None, 5, 64), dtype=float32)\n",
      "user_embedding_final:  Tensor(\"ExpandDims_4:0\", shape=(None, 1, 64), dtype=float32)\n",
      "item_embedding_layer:  Tensor(\"transpose_31:0\", shape=(None, 64, 11), dtype=float32)\n",
      "Tensor(\"MatMul_26:0\", shape=(None, 1, 11), dtype=float32)\n",
      "Tensor(\"Softmax_26:0\", shape=(None, 1, 11), dtype=float32)\n",
      "Model: \"model_26\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "user_click_item_seq_input_layer [(None, 50)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id_input_layer (InputLayer [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "gender_input_layer (InputLayer) [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "age_input_layer (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "occupation_input_layer (InputLa [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zip_input_layer (InputLayer)    [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "item_id_embedding_layer (Embedd multiple             237248      pos_item_sample_input_layer[0][0]\n",
      "                                                                 neg_item_sample_input_layer[0][0]\n",
      "                                                                 user_click_item_seq_input_layer[0\n",
      "__________________________________________________________________________________________________\n",
      "user_click_item_seq_length_inpu [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "user_id_embedding_layer (Embedd (None, 1, 64)        386624      user_id_input_layer[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "gender_embedding_layer (Embeddi (None, 1, 64)        192         gender_input_layer[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "age_embedding_layer (Embedding) (None, 1, 64)        512         age_input_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "occupation_embedding_layer (Emb (None, 1, 64)        1408        occupation_input_layer[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "zip_embedding_layer (Embedding) (None, 1, 64)        220160      zip_input_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "sequence_pooling_layer_52 (Sequ (None, 1, 64)        0           item_id_embedding_layer[2][0]    \n",
      "                                                                 user_click_item_seq_length_input_\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_124 (Concatenate)   (None, 1, 384)       0           user_id_embedding_layer[0][0]    \n",
      "                                                                 gender_embedding_layer[0][0]     \n",
      "                                                                 age_embedding_layer[0][0]        \n",
      "                                                                 occupation_embedding_layer[0][0] \n",
      "                                                                 zip_embedding_layer[0][0]        \n",
      "                                                                 sequence_pooling_layer_52[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "flatten_46 (Flatten)            (None, 384)          0           concatenate_124[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 5, 384)       0           flatten_46[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "capsule_layer_55 (CapsuleLayer) (None, 5, 64)        4346        item_id_embedding_layer[2][0]    \n",
      "                                                                 user_click_item_seq_length_input_\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_125 (Concatenate)   (None, 5, 448)       0           lambda_45[0][0]                  \n",
      "                                                                 capsule_layer_55[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "FC_1 (Dense)                    (None, 5, 128)       57472       concatenate_125[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "pos_item_sample_input_layer (In [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "neg_item_sample_input_layer (In [(None, 10)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "FC_2 (Dense)                    (None, 5, 64)        8256        FC_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "label_aware_attention_40 (Label (None, 64)           0           FC_2[0][0]                       \n",
      "                                                                 item_id_embedding_layer[0][0]    \n",
      "                                                                 user_click_item_seq_length_input_\n",
      "__________________________________________________________________________________________________\n",
      "concatenate_126 (Concatenate)   (None, 11, 64)       0           item_id_embedding_layer[0][0]    \n",
      "                                                                 item_id_embedding_layer[1][0]    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_ExpandDims_4 (Tenso [(None, 1, 64)]      0           label_aware_attention_40[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_transpose_31 (Tenso [(None, 64, 11)]     0           concatenate_126[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_MatMul_26 (TensorFl [(None, 1, 11)]      0           tf_op_layer_ExpandDims_4[0][0]   \n",
      "                                                                 tf_op_layer_transpose_31[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_Softmax_26 (TensorF [(None, 1, 11)]      0           tf_op_layer_MatMul_26[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 916,218\n",
      "Trainable params: 915,968\n",
      "Non-trainable params: 250\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "re_model = mind()\n",
    "re_model.load_weights('mind_model.h5')\n",
    "\n",
    "print(re_model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id, gender, age, occupation, zip, \\\n",
    "        hist_movie_id, hist_len, pos_movie_id, neg_movie_id = init_output()\n",
    "\n",
    "with open(\"test.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "\n",
    "        buf = line.strip().split('\\t')\n",
    "\n",
    "        user_id.append(int(buf[0]))\n",
    "        gender.append(int(buf[1]))\n",
    "        age.append(int(buf[2]))\n",
    "        occupation.append(int(buf[3]))\n",
    "        zip.append(int(buf[4]))\n",
    "        hist_movie_id.append(np.array([int(i) for i in buf[5].strip().split(\",\")]))\n",
    "        hist_len.append(int(buf[6]))\n",
    "        pos_movie_id.append(int(buf[7]))\n",
    "        \n",
    "\n",
    "user_id = np.array(user_id, dtype='int32')\n",
    "gender = np.array(gender, dtype='int32')\n",
    "age = np.array(age, dtype='int32')\n",
    "occupation = np.array(occupation, dtype='int32')\n",
    "zip = np.array(zip, dtype='int32')\n",
    "hist_movie_id = np.array(hist_movie_id, dtype='int32')\n",
    "hist_len = np.array(hist_len, dtype='int32')\n",
    "pos_movie_id = np.array(pos_movie_id, dtype='int32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 5, 64)\n",
      "(3707, 1, 64)\n",
      "[[0.         0.14731093 0.13900717 0.         0.         1.478808\n",
      "  0.         0.18150645 0.80898654 0.         0.         0.\n",
      "  0.         0.         0.         0.15728728 0.08639187 0.42935494\n",
      "  0.7397017  0.06567826 0.41014    0.         0.16195668 1.5011536\n",
      "  0.         0.         0.         0.05010591 0.         0.19825594\n",
      "  0.         0.         0.9191648  0.7207551  0.67062324 0.6644707\n",
      "  0.47457296 0.13724752 0.26177412 0.13435438 0.10145954 0.\n",
      "  0.28838137 0.57013756 0.         0.         0.         0.\n",
      "  0.1595294  0.7744232  0.04367758 0.52349055 0.63513637 0.\n",
      "  0.         0.09334061 0.0245292  0.         0.8633623  0.\n",
      "  0.         0.42910543 0.         1.0345823 ]\n",
      " [0.         0.         0.24033175 0.         0.         1.5294596\n",
      "  0.         0.0761693  0.90816593 0.         0.06147628 0.1498693\n",
      "  0.         0.         0.         0.22493754 0.         0.46198222\n",
      "  0.66455394 0.         0.4079227  0.         0.16429693 1.5069313\n",
      "  0.         0.         0.02239586 0.13046503 0.         0.13231997\n",
      "  0.         0.         1.0940899  0.65151983 0.7221997  0.51830554\n",
      "  0.41334137 0.15709458 0.32423824 0.17478804 0.19554625 0.\n",
      "  0.3039636  0.698857   0.         0.         0.         0.\n",
      "  0.28589395 0.76862556 0.         0.5648317  0.58260715 0.0660167\n",
      "  0.         0.13349497 0.02509666 0.         0.9027546  0.\n",
      "  0.10378504 0.3329178  0.         1.1952631 ]]\n",
      "(3707, 64)\n"
     ]
    }
   ],
   "source": [
    "# Generate user features for testing and full item features for retrieval\n",
    "\n",
    "test_user_model_input = [user_id, gender, age, occupation, zip, hist_movie_id, hist_len]\n",
    "all_item_model_input = list(range(0, 3706+1))\n",
    "\n",
    "user_embedding_model = Model(inputs=re_model.user_input, outputs=re_model.user_embedding)\n",
    "item_embedding_model = Model(inputs=re_model.item_input, outputs=re_model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test_user_model_input)\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "print(item_embs.shape)\n",
    "\n",
    "\n",
    "user_embs = np.reshape(user_embs, (-1, 64))\n",
    "item_embs = np.reshape(item_embs, (-1, 64))\n",
    "\n",
    "print(user_embs[:2])\n",
    "print(item_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6040, 5, 64)\n",
      "(3707, 1, 64)\n",
      "[[0.         0.14731093 0.13900717 0.         0.         1.478808\n",
      "  0.         0.18150645 0.80898654 0.         0.         0.\n",
      "  0.         0.         0.         0.15728728 0.08639187 0.42935494\n",
      "  0.7397017  0.06567826 0.41014    0.         0.16195668 1.5011536\n",
      "  0.         0.         0.         0.05010591 0.         0.19825594\n",
      "  0.         0.         0.9191648  0.7207551  0.67062324 0.6644707\n",
      "  0.47457296 0.13724752 0.26177412 0.13435438 0.10145954 0.\n",
      "  0.28838137 0.57013756 0.         0.         0.         0.\n",
      "  0.1595294  0.7744232  0.04367758 0.52349055 0.63513637 0.\n",
      "  0.         0.09334061 0.0245292  0.         0.8633623  0.\n",
      "  0.         0.42910543 0.         1.0345823 ]\n",
      " [0.         0.         0.24033175 0.         0.         1.5294596\n",
      "  0.         0.0761693  0.90816593 0.         0.06147628 0.1498693\n",
      "  0.         0.         0.         0.22493754 0.         0.46198222\n",
      "  0.66455394 0.         0.4079227  0.         0.16429693 1.5069313\n",
      "  0.         0.         0.02239586 0.13046503 0.         0.13231997\n",
      "  0.         0.         1.0940899  0.65151983 0.7221997  0.51830554\n",
      "  0.41334137 0.15709458 0.32423824 0.17478804 0.19554625 0.\n",
      "  0.3039636  0.698857   0.         0.         0.         0.\n",
      "  0.28589395 0.76862556 0.         0.5648317  0.58260715 0.0660167\n",
      "  0.         0.13349497 0.02509666 0.         0.9027546  0.\n",
      "  0.10378504 0.3329178  0.         1.1952631 ]]\n",
      "(3707, 64)\n"
     ]
    }
   ],
   "source": [
    "# Generate user features for testing and full item features for retrieval\n",
    "\n",
    "test_user_model_input = [user_id, gender, age, occupation, zip, hist_movie_id, hist_len]\n",
    "all_item_model_input = list(range(0, 3706+1))\n",
    "\n",
    "user_embedding_model = Model(inputs=model.user_input, outputs=model.user_embedding)\n",
    "item_embedding_model = Model(inputs=model.item_input, outputs=model.item_embedding)\n",
    "\n",
    "user_embs = user_embedding_model.predict(test_user_model_input)\n",
    "item_embs = item_embedding_model.predict(all_item_model_input, batch_size=2 ** 12)\n",
    "\n",
    "print(user_embs.shape)\n",
    "print(item_embs.shape)\n",
    "\n",
    "\n",
    "user_embs = np.reshape(user_embs, (-1, 64))\n",
    "item_embs = np.reshape(item_embs, (-1, 64))\n",
    "\n",
    "print(user_embs[:2])\n",
    "print(item_embs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named '_swigfaiss'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/notebook/.custom/tensorflow-1.13.1-notebook-cpu/pylib/base/faiss/swigfaiss.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mmodule_from_spec\u001b[0;34m(spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libopenblas.so.0: cannot open shared object file: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-77b8d84685fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mfaiss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeepmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrecall_N\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/.custom/tensorflow-1.13.1-notebook-cpu/pylib/base/faiss/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m# we import * so that the symbol X can be accessed as faiss.X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mswigfaiss\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m __version__ = \"%d.%d.%d\" % (FAISS_VERSION_MAJOR,\n",
      "\u001b[0;32m/notebook/.custom/tensorflow-1.13.1-notebook-cpu/pylib/base/faiss/swigfaiss.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_swigfaiss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0m_swigfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0m_swig_python_version_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/notebook/.custom/tensorflow-1.13.1-notebook-cpu/pylib/base/faiss/swigfaiss.py\u001b[0m in \u001b[0;36mswig_import_helper\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_swigfaiss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0m_swigfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mswig_import_helper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named '_swigfaiss'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import faiss\n",
    "from tqdm import tqdm\n",
    "from deepmatch.utils import recall_N\n",
    "\n",
    "embedding_dim = 64\n",
    "index = faiss.IndexFlatIP(embedding_dim)\n",
    "index.add(item_embs)\n",
    "\n",
    "D, I = index.search(np.ascontiguousarray(user_embs), 50)\n",
    "s = []\n",
    "hit = 0\n",
    "\n",
    "for i, uid in tqdm(enumerate(user_id)):\n",
    "    try:\n",
    "        pred = [all_item_model_input[x] for x in I[i]]\n",
    "        filter_item = None\n",
    "        recall_score = recall_N(pos_movie_id[i], pred, N=50)\n",
    "        s.append(recall_score)\n",
    "        if pos_movie_id[i] in pred:\n",
    "            hit += 1\n",
    "    except:\n",
    "        print(i)\n",
    "        \n",
    "print(\"\")\n",
    "print(\"recall\", np.mean(s))\n",
    "print(\"hit rate\", hit / len(user_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
